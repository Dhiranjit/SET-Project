{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8d09042",
   "metadata": {},
   "source": [
    "# Stock Data & Sentiment Features Merger\n",
    "\n",
    "Merge stock market data with sentiment analysis features for Nifty top 10 stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5219bca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "064e9b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nifty_top_tickers = [\n",
    "    \"RELIANCE\",\n",
    "    \"HDFCBANK\",\n",
    "    \"TCS\",\n",
    "    \"BHARTIARTL\",\n",
    "    \"ICICIBANK\",\n",
    "    \"SBIN\",\n",
    "    \"INFY\",\n",
    "    \"KOTAKBANK\",\n",
    "    \"BAJFINANCE\",\n",
    "    \"HINDUNILVR\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d478e76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "stock_data_dir = 'stock_data_daily_processed'\n",
    "sentiment_features_dir = 'final_sentiment_features'\n",
    "output_dir = 'merged_stock_sentiment_data'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b352c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_stock_sentiment_data(ticker):\n",
    "    \"\"\"\n",
    "    Merge stock data with sentiment features for a given ticker.\n",
    "    Ensures proper date alignment and correct column names.\n",
    "    \"\"\"\n",
    "    # Load stock data - row 0 has feature names, skip rows 1-2 (Ticker and Date labels)\n",
    "    stock_file = f'{stock_data_dir}/{ticker}_daily_data.csv'\n",
    "    stock_df = pd.read_csv(stock_file, header=0, skiprows=[1, 2])\n",
    "    \n",
    "    # Rename first column to 'Date'\n",
    "    stock_df.rename(columns={stock_df.columns[0]: 'Date'}, inplace=True)\n",
    "    \n",
    "    # Load sentiment features\n",
    "    sentiment_file = f'{sentiment_features_dir}/{ticker}_features.csv'\n",
    "    sentiment_df = pd.read_csv(sentiment_file)\n",
    "    \n",
    "    # Convert date columns to datetime\n",
    "    stock_df['Date'] = pd.to_datetime(stock_df['Date'])\n",
    "    sentiment_df['date'] = pd.to_datetime(sentiment_df['date'])\n",
    "    \n",
    "    # Merge on date\n",
    "    merged_df = pd.merge(\n",
    "        stock_df, \n",
    "        sentiment_df, \n",
    "        left_on='Date', \n",
    "        right_on='date', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Drop the duplicate date column\n",
    "    merged_df = merged_df.drop('date', axis=1)\n",
    "    \n",
    "    # Fill missing sentiment values with 0\n",
    "    sentiment_cols = ['avg_polarity', 'avg_confidence', 'news_article_count', \n",
    "                      'sentiment_change', 'momentum_3d', 'momentum_5d']\n",
    "    merged_df[sentiment_cols] = merged_df[sentiment_cols].fillna(0)\n",
    "    \n",
    "    # Convert numeric columns to appropriate types\n",
    "    for col in merged_df.columns:\n",
    "        if col != 'Date':\n",
    "            merged_df[col] = pd.to_numeric(merged_df[col], errors='coerce')\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59136d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing RELIANCE...\n",
      "  ✓ Saved: merged_stock_sentiment_data/RELIANCE_merged_data.csv - Shape: (1461, 48)\n",
      "\n",
      "Processing HDFCBANK...\n",
      "  ✓ Saved: merged_stock_sentiment_data/HDFCBANK_merged_data.csv - Shape: (1461, 48)\n",
      "\n",
      "Processing TCS...\n",
      "  ✓ Saved: merged_stock_sentiment_data/TCS_merged_data.csv - Shape: (1461, 48)\n",
      "\n",
      "Processing BHARTIARTL...\n",
      "  ✓ Saved: merged_stock_sentiment_data/HDFCBANK_merged_data.csv - Shape: (1461, 48)\n",
      "\n",
      "Processing TCS...\n",
      "  ✓ Saved: merged_stock_sentiment_data/TCS_merged_data.csv - Shape: (1461, 48)\n",
      "\n",
      "Processing BHARTIARTL...\n",
      "  ✓ Saved: merged_stock_sentiment_data/BHARTIARTL_merged_data.csv - Shape: (1461, 48)\n",
      "\n",
      "Processing ICICIBANK...\n",
      "  ✓ Saved: merged_stock_sentiment_data/ICICIBANK_merged_data.csv - Shape: (1461, 48)\n",
      "\n",
      "Processing SBIN...\n",
      "  ✓ Saved: merged_stock_sentiment_data/BHARTIARTL_merged_data.csv - Shape: (1461, 48)\n",
      "\n",
      "Processing ICICIBANK...\n",
      "  ✓ Saved: merged_stock_sentiment_data/ICICIBANK_merged_data.csv - Shape: (1461, 48)\n",
      "\n",
      "Processing SBIN...\n",
      "  ✓ Saved: merged_stock_sentiment_data/SBIN_merged_data.csv - Shape: (1461, 48)\n",
      "\n",
      "Processing INFY...\n",
      "  ✓ Saved: merged_stock_sentiment_data/INFY_merged_data.csv - Shape: (1461, 48)\n",
      "\n",
      "Processing KOTAKBANK...\n",
      "  ✓ Saved: merged_stock_sentiment_data/SBIN_merged_data.csv - Shape: (1461, 48)\n",
      "\n",
      "Processing INFY...\n",
      "  ✓ Saved: merged_stock_sentiment_data/INFY_merged_data.csv - Shape: (1461, 48)\n",
      "\n",
      "Processing KOTAKBANK...\n",
      "  ✓ Saved: merged_stock_sentiment_data/KOTAKBANK_merged_data.csv - Shape: (1461, 48)\n",
      "\n",
      "Processing BAJFINANCE...\n",
      "  ✓ Saved: merged_stock_sentiment_data/BAJFINANCE_merged_data.csv - Shape: (1461, 48)\n",
      "\n",
      "Processing HINDUNILVR...\n",
      "  ✓ Saved: merged_stock_sentiment_data/HINDUNILVR_merged_data.csv - Shape: (1461, 48)\n",
      "\n",
      "✓ All files merged and saved successfully!\n",
      "  ✓ Saved: merged_stock_sentiment_data/KOTAKBANK_merged_data.csv - Shape: (1461, 48)\n",
      "\n",
      "Processing BAJFINANCE...\n",
      "  ✓ Saved: merged_stock_sentiment_data/BAJFINANCE_merged_data.csv - Shape: (1461, 48)\n",
      "\n",
      "Processing HINDUNILVR...\n",
      "  ✓ Saved: merged_stock_sentiment_data/HINDUNILVR_merged_data.csv - Shape: (1461, 48)\n",
      "\n",
      "✓ All files merged and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Process all tickers and save merged data\n",
    "for ticker in nifty_top_tickers:\n",
    "    print(f\"Processing {ticker}...\")\n",
    "    \n",
    "    # Merge the data\n",
    "    merged_df = merge_stock_sentiment_data(ticker)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_file = f'{output_dir}/{ticker}_merged_data.csv'\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "    print(f\"  ✓ Saved: {output_file} - Shape: {merged_df.shape}\\n\")\n",
    "\n",
    "print(\"✓ All files merged and saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57af1874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MERGED DATA VERIFICATION\n",
      "================================================================================\n",
      "\n",
      "Shape: (1461, 48)\n",
      "Date range: 2018-01-30 to 2023-12-29\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "COLUMN STRUCTURE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Total columns: 48\n",
      "\n",
      "Stock features (41): ['Close', 'High', 'Low', 'Open', 'Volume', 'log_return', 'return_lag_1', 'return_lag_2', 'return_lag_3', 'return_lag_5', 'price_change_5d', 'price_change_10d', 'price_change_20d', 'high_low_ratio', 'open_close_ratio', 'volatility_5d', 'volatility_10d', 'volatility_20d', 'volume_change', 'volume_ma_5', 'volume_ma_20', 'volume_ratio_5d', 'volume_ratio_20d', 'price_volume_trend', 'sma_5', 'sma_10', 'sma_20', 'ema_10', 'ema_20', 'price_to_sma_5', 'price_to_sma_20', 'rsi_14', 'macd', 'macd_signal', 'macd_hist', 'bollinger_upper', 'bollinger_lower', 'bollinger_mid', 'bollinger_width', 'bollinger_position', 'target']\n",
      "\n",
      "Sentiment features (6): ['avg_polarity', 'avg_confidence', 'news_article_count', 'sentiment_change', 'momentum_3d', 'momentum_5d']\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATA SAMPLE - First 5 rows with key columns\n",
      "--------------------------------------------------------------------------------\n",
      "         Date       Close    Volume  log_return  target  avg_polarity  \\\n",
      "0  2018-01-30  163.464920   6801040   -0.021747       0      0.000000   \n",
      "1  2018-01-31  163.411362  13322250   -0.000328       1      0.000000   \n",
      "2  2018-02-01  168.436874  19398120    0.030290       0      0.000000   \n",
      "3  2018-02-02  158.643967  16450450   -0.059899       0      0.799875   \n",
      "4  2018-02-05  156.311386  14721640   -0.014812       1      0.000000   \n",
      "\n",
      "   avg_confidence  news_article_count  \n",
      "0        0.000000                 0.0  \n",
      "1        0.000000                 0.0  \n",
      "2        0.000000                 0.0  \n",
      "3        0.799875                 1.0  \n",
      "4        0.835626                 1.0  \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "SENTIMENT DATA ALIGNMENT CHECK\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Rows with news articles:\n",
      "          Date       Close    Volume  log_return  target  avg_polarity  \\\n",
      "3   2018-02-02  158.643967  16450450   -0.059899       0      0.799875   \n",
      "4   2018-02-05  156.311386  14721640   -0.014812       1      0.000000   \n",
      "11  2018-02-15  163.333466  11771160    0.004243       0      0.000000   \n",
      "17  2018-02-23  159.082214   7114740    0.020441       1      0.000000   \n",
      "30  2018-03-15  168.125229   7391870    0.009400       0      0.949850   \n",
      "38  2018-03-27  172.624771  16702390    0.017558       0      0.000000   \n",
      "39  2018-03-28  172.147552   9869600   -0.002768       1      0.874337   \n",
      "42  2018-04-04  180.197098  17934410    0.008658       1      0.930843   \n",
      "70  2018-05-15  185.237213  15703020    0.019887       1      0.000000   \n",
      "71  2018-05-16  186.990280   9528360    0.009419       1      0.000000   \n",
      "\n",
      "    avg_confidence  news_article_count  \n",
      "3         0.799875                 1.0  \n",
      "4         0.835626                 1.0  \n",
      "11        0.885345                 2.0  \n",
      "17        0.901144                 1.0  \n",
      "30        0.949850                 1.0  \n",
      "38        0.930072                 1.0  \n",
      "39        0.874337                 1.0  \n",
      "42        0.930843                 1.0  \n",
      "70        0.918161                 1.0  \n",
      "71        0.946999                 1.0  \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "MISSING VALUES CHECK\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "✓ No missing values found!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "SENTIMENT FEATURES STATISTICS\n",
      "--------------------------------------------------------------------------------\n",
      "       avg_polarity  avg_confidence  news_article_count  sentiment_change  \\\n",
      "count   1461.000000     1461.000000         1461.000000       1461.000000   \n",
      "mean       0.087495        0.459593            1.708419          0.019042   \n",
      "std        0.474414        0.434028            3.554063          0.619089   \n",
      "min       -0.975085        0.000000            0.000000         -1.924607   \n",
      "25%        0.000000        0.000000            0.000000         -0.142287   \n",
      "50%        0.000000        0.662466            1.000000          0.000000   \n",
      "75%        0.294137        0.895850            2.000000          0.236002   \n",
      "max        0.959533        0.975085           49.000000          1.917606   \n",
      "\n",
      "       momentum_3d  momentum_5d  \n",
      "count  1461.000000  1461.000000  \n",
      "mean      0.070240     0.062160  \n",
      "std       0.273664     0.213115  \n",
      "min      -0.886229    -0.769273  \n",
      "25%      -0.003041    -0.026963  \n",
      "50%       0.000000     0.000000  \n",
      "75%       0.273477     0.186139  \n",
      "max       0.940907     0.658132  \n",
      "\n",
      "================================================================================\n",
      "✓ MERGE VERIFICATION COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify the merged data quality\n",
    "sample = pd.read_csv(f'{output_dir}/BAJFINANCE_merged_data.csv')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MERGED DATA VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nShape: {sample.shape}\")\n",
    "print(f\"Date range: {sample['Date'].min()} to {sample['Date'].max()}\")\n",
    "\n",
    "print(f\"\\n{'-'*80}\")\n",
    "print(\"COLUMN STRUCTURE\")\n",
    "print(f\"{'-'*80}\")\n",
    "print(f\"\\nTotal columns: {len(sample.columns)}\")\n",
    "print(f\"\\nStock features (41): {sample.columns[1:42].tolist()}\")\n",
    "print(f\"\\nSentiment features (6): {sample.columns[42:].tolist()}\")\n",
    "\n",
    "print(f\"\\n{'-'*80}\")\n",
    "print(\"DATA SAMPLE - First 5 rows with key columns\")\n",
    "print(f\"{'-'*80}\")\n",
    "display_cols = ['Date', 'Close', 'Volume', 'log_return', 'target', \n",
    "                'avg_polarity', 'avg_confidence', 'news_article_count']\n",
    "print(sample[display_cols].head())\n",
    "\n",
    "print(f\"\\n{'-'*80}\")\n",
    "print(\"SENTIMENT DATA ALIGNMENT CHECK\")\n",
    "print(f\"{'-'*80}\")\n",
    "print(\"\\nRows with news articles:\")\n",
    "news_rows = sample[sample['news_article_count'] > 0][display_cols].head(10)\n",
    "print(news_rows)\n",
    "\n",
    "print(f\"\\n{'-'*80}\")\n",
    "print(\"MISSING VALUES CHECK\")\n",
    "print(f\"{'-'*80}\")\n",
    "missing = sample.isnull().sum()\n",
    "if missing.sum() > 0:\n",
    "    print(\"\\nColumns with missing values:\")\n",
    "    print(missing[missing > 0])\n",
    "else:\n",
    "    print(\"\\n✓ No missing values found!\")\n",
    "\n",
    "print(f\"\\n{'-'*80}\")\n",
    "print(\"SENTIMENT FEATURES STATISTICS\")\n",
    "print(f\"{'-'*80}\")\n",
    "sentiment_cols = ['avg_polarity', 'avg_confidence', 'news_article_count', \n",
    "                  'sentiment_change', 'momentum_3d', 'momentum_5d']\n",
    "print(sample[sentiment_cols].describe())\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"✓ MERGE VERIFICATION COMPLETE\")\n",
    "print(f\"{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
